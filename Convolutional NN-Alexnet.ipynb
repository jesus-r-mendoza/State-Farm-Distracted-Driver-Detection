{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "\n",
    "\n",
    "img_width, img_height = 640, 480\n",
    "\n",
    "# training path\n",
    "DATADIR = \"/Users/crisramos/Desktop/Deep Learning/Project FArmerINsurance/imgs/train\"\n",
    "categories= [ 'c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\n",
    "\n",
    "for category in categories:\n",
    "    path  = os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img_array,cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "#307200 size of pics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68 67 67 ... 45 56 91]\n",
      " [70 69 69 ... 76 73 69]\n",
      " [72 71 71 ... 86 78 74]\n",
      " ...\n",
      " [ 5  5  5 ... 15 15 14]\n",
      " [ 5  5  5 ... 14 15 16]\n",
      " [ 5  5  5 ... 13 15 17]]\n"
     ]
    }
   ],
   "source": [
    "print(img_array)\n",
    "#IMG_SIZE = 480*640 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "def create_td():\n",
    "    for category in categories:\n",
    "        path  = os.path.join(DATADIR, category)\n",
    "        class_num = categories.index(category)\n",
    "        i=0\n",
    "        for img in os.listdir(path):\n",
    "            img_array=cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "            training_data.append([img_array,class_num])\n",
    "            i+=1\n",
    "            if i >1300:\n",
    "                break\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13010\n"
     ]
    }
   ],
   "source": [
    "create_td()\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "5\n",
      "8\n",
      "2\n",
      "0\n",
      "9\n",
      "4\n",
      "4\n",
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(training_data)\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= []\n",
    "y=[]\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X= np.array(X).reshape(-1, 480,640,1)  #if its color 1 has tobe 3!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for saving purposes\n",
    "#**********************************************\n",
    "\n",
    "# file too big wont save anyway.............\n",
    "\n",
    "#**********************************************\n",
    "import pickle \n",
    "\n",
    "#pickle_out = open(\"X.pickle\",\"wb\")\n",
    "#pickle.dump(X, pickle_out)\n",
    "#pickle_out.close()\n",
    "\n",
    "#pickle_out = open(\"y.pickle\",\"wb\")\n",
    "#pickle.dump(y, pickle_out)\n",
    "#pickle_out.close()\n",
    "#print(X[0])\n",
    "#print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_in= open(\"X.pickle\",\"rb\")\n",
    "#X = pickle.load(pickle_in)\n",
    "\n",
    "#pickle_in= open(\"y.pickle\",\"rb\")\n",
    "#y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y = np_utils.to_categorical(y, 10)\n",
    "X = X/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready..\n"
     ]
    }
   ],
   "source": [
    "print('ready..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input= (480, 640, 1)\n",
      "(None, 118, 158, 32)\n",
      "(None, 58, 78, 32)\n"
     ]
    }
   ],
   "source": [
    "# CNN first layer (with 32 3x3 filter):\n",
    "print('input=',X.shape[1:])\n",
    "model.add(   Conv2D(32,(11,11),input_shape= X.shape[1:], strides=4)  )\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)# 480 -11 +3 / 3 + 1\n",
    "\n",
    "# pooling layer 1\n",
    "model.add(MaxPooling2D(pool_size= (3,3),strides=2))\n",
    "print(model.output_shape) # 118 - 3 +1 /3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 58, 78, 32)\n",
      "(None, 28, 38, 32)\n",
      "(None, 28, 38, 32)\n",
      "(None, 28, 38, 32)\n",
      "(None, 28, 38, 32)\n",
      "(None, 13, 18, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2 Conv lsyer\n",
    "model.add(Conv2D(32,(5,5),strides=1,padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "# pooling layer 2\n",
    "model.add(MaxPooling2D(pool_size= (3,3),strides=2))\n",
    "print(model.output_shape)\n",
    "\n",
    "# 3 Conv lsyer\n",
    "model.add(Conv2D(32,(3,3),strides=1,padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "# 4 Conv lsyer\n",
    "model.add(Conv2D(32,(3,3),strides=1,padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "# 5 Conv lsyer\n",
    "model.add(Conv2D(32,(3,3),strides=1,padding='same'))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "# pooling layer 3\n",
    "model.add(MaxPooling2D(pool_size= (3,3),strides=2))\n",
    "print(model.output_shape)\n",
    "# Dropout layer to avoid overfiiting\n",
    "model.add(Dropout(0.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 7488)\n",
      "(None, 1028)\n",
      "(None, 1028)\n",
      "(None, 1028)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# output Fully connected Dense layers:\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(1028))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(1028))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "print(model.output_shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 118, 158, 32)      3904      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 118, 158, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 58, 78, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 58, 78, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 58, 78, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 28, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 28, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 28, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 28, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 28, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 28, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 28, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 13, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 7488)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1028)              7698692   \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 1028)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1028)              0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1028)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1028)              1057812   \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1028)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                10290     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 8,824,074\n",
      "Trainable params: 8,824,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import categorical_accuracy\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[categorical_accuracy])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import time\n",
    "name= \"convNN 5conv layers 480 640\".format(int(time.time()))\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name), batch_size = 32, update_freq= 'batch',write_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11709 samples, validate on 1301 samples\n",
      "Epoch 1/6\n",
      " 1088/11709 [=>............................] - ETA: 27:46 - loss: 2.3081 - categorical_accuracy: 0.0993"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-c51517531eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m fitted_model= model.fit(X,y, epochs= 6, validation_split=.1,\n\u001b[0;32m----> 5\u001b[0;31m                         batch_size=32, verbose= 1,callbacks =[es,tensorboard])\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "fitted_model= model.fit(X,y, epochs= 6, validation_split=.1,\n",
    "                        batch_size=32, verbose= 1,callbacks =[es,tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "categories= [ 'c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\n",
    "\n",
    "\n",
    "\n",
    "path='/Users/crisramos/Desktop/Deep Learning/Project FArmerINsurance/imgs/test'# testing path\n",
    "testing_set=[]\n",
    "c=0\n",
    "im='img_11.jpg'\n",
    "img_arr=cv2.imread(os.path.join(path,im), cv2.IMREAD_GRAYSCALE)\n",
    "#img_arr =cv2.resize(img_arr,(300,300))\n",
    "testing_set.append(img_arr)\n",
    "#img_array=cv2.imread(os.path.join(path,img), cv2.IMREAD_COLOR)\n",
    "plt.imshow(img_arr,cmap=\"gray\")\n",
    "\n",
    "#plt.imshow(img_array,cmap=\"gray\")\n",
    "plt.show()\n",
    "           \n",
    "    \n",
    "X_test= []\n",
    "for d in testing_set:\n",
    "    X_test.append(d)\n",
    "    \n",
    "    \n",
    "X_test= np.array(X_test).reshape(-1, 480,640,1)  #if its color 1 has tobe 3!!! \n",
    "\n",
    "     \n",
    "#X_test = np.array(testing_set).reshape(-1, 480,640,1)    \n",
    "#print(X_test.shape)       \n",
    "\n",
    "#X_test = X_test.reshape(len(X_test),-1)\n",
    "\n",
    "#X_test_new = my_pca.transform(X_test)\n",
    "#X_test_new= np.array(X_test).reshape(-1, 10,100,1)\n",
    "\n",
    "\n",
    "prediction=model.predict(X_test)\n",
    "print( \"  0 1  2  3  4  5  6  7  8  9\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(path,im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
